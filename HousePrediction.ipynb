{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building a Neural Network for House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook was created from code and data found [here](https://github.com/josephlee94/intuitive-deep-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploring and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We first have to read in the CSV file that we've been given. We'll use a package called pandas for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Data and Splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "block:prepdata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting files\n",
      "reading files\n"
     ]
    }
   ],
   "source": [
    "#path = \"data/\"\n",
    "path = \"/home/jovyan/\"\n",
    "#PREDICTION_LABEL = 'Survived'\n",
    "url1 = 'https://raw.githubusercontent.com/josephlee94/intuitive-deep-learning/master/Part%201%3A%20Predicting%20House%20Prices/housepricedata.csv'\n",
    "print(\"getting files\")\n",
    "urllib.request.urlretrieve(url1, path + \"housepricedata.csv\")\n",
    "\n",
    "print(\"reading files\")\n",
    "\n",
    "df = pd.read_csv(path + \"housepricedata.csv\")\n",
    "dataset = df.values\n",
    "#Split data to features X and Lable Y. The Label is what we want to predict, is the house price above median price?\n",
    "X = dataset[:,0:10]\n",
    "Y = dataset[:,10]\n",
    "# Scale the date between 0 and 1 to make it easier to train\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "#Split the data set for training and validating. For both features and input\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building and Training Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will be using Keras to build our architecture. Let's import the code from Keras that we will need to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "block:trainmodel",
     "prev:prepdata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.6903 - acc: 0.4951 - val_loss: 0.6873 - val_acc: 0.5342\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 0.6875 - acc: 0.4980 - val_loss: 0.6849 - val_acc: 0.5342\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 0.6846 - acc: 0.5059 - val_loss: 0.6823 - val_acc: 0.5388\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.6817 - acc: 0.5157 - val_loss: 0.6797 - val_acc: 0.5708\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6790 - acc: 0.6047 - val_loss: 0.6773 - val_acc: 0.6530\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.6763 - acc: 0.6262 - val_loss: 0.6750 - val_acc: 0.7215\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.6737 - acc: 0.7231 - val_loss: 0.6726 - val_acc: 0.7580\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.6710 - acc: 0.7515 - val_loss: 0.6702 - val_acc: 0.7763\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.6683 - acc: 0.7485 - val_loss: 0.6676 - val_acc: 0.8174\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.6654 - acc: 0.7681 - val_loss: 0.6649 - val_acc: 0.8311\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.6623 - acc: 0.7759 - val_loss: 0.6621 - val_acc: 0.8493\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.6592 - acc: 0.8239 - val_loss: 0.6590 - val_acc: 0.8493\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.6558 - acc: 0.8229 - val_loss: 0.6557 - val_acc: 0.8493\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6523 - acc: 0.8131 - val_loss: 0.6523 - val_acc: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 0.6485 - acc: 0.8072 - val_loss: 0.6489 - val_acc: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6445 - acc: 0.8356 - val_loss: 0.6449 - val_acc: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.6402 - acc: 0.8200 - val_loss: 0.6410 - val_acc: 0.8447\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6358 - acc: 0.8317 - val_loss: 0.6366 - val_acc: 0.8447\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.6309 - acc: 0.8474 - val_loss: 0.6319 - val_acc: 0.8493\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6259 - acc: 0.8415 - val_loss: 0.6270 - val_acc: 0.8447\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.6204 - acc: 0.8386 - val_loss: 0.6220 - val_acc: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.6145 - acc: 0.8386 - val_loss: 0.6167 - val_acc: 0.8356\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.6085 - acc: 0.8454 - val_loss: 0.6110 - val_acc: 0.8356\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.6020 - acc: 0.8434 - val_loss: 0.6049 - val_acc: 0.8356\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.5954 - acc: 0.8513 - val_loss: 0.5986 - val_acc: 0.8402\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.5882 - acc: 0.8454 - val_loss: 0.5925 - val_acc: 0.8356\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.5810 - acc: 0.8591 - val_loss: 0.5854 - val_acc: 0.8356\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.5731 - acc: 0.8601 - val_loss: 0.5781 - val_acc: 0.8402\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.5652 - acc: 0.8532 - val_loss: 0.5713 - val_acc: 0.8311\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.5569 - acc: 0.8620 - val_loss: 0.5638 - val_acc: 0.8311\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.5485 - acc: 0.8571 - val_loss: 0.5565 - val_acc: 0.8356\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.5397 - acc: 0.8650 - val_loss: 0.5488 - val_acc: 0.8356\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.5309 - acc: 0.8630 - val_loss: 0.5415 - val_acc: 0.8356\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.5218 - acc: 0.8650 - val_loss: 0.5338 - val_acc: 0.8402\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.5125 - acc: 0.8650 - val_loss: 0.5247 - val_acc: 0.8356\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.5036 - acc: 0.8630 - val_loss: 0.5179 - val_acc: 0.8402\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.4943 - acc: 0.8659 - val_loss: 0.5101 - val_acc: 0.8402\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.4851 - acc: 0.8699 - val_loss: 0.5023 - val_acc: 0.8402\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.4759 - acc: 0.8669 - val_loss: 0.4945 - val_acc: 0.8402\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.4669 - acc: 0.8679 - val_loss: 0.4868 - val_acc: 0.8402\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.4580 - acc: 0.8679 - val_loss: 0.4810 - val_acc: 0.8356\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.4493 - acc: 0.8708 - val_loss: 0.4754 - val_acc: 0.8402\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.4409 - acc: 0.8669 - val_loss: 0.4670 - val_acc: 0.8356\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.4326 - acc: 0.8689 - val_loss: 0.4613 - val_acc: 0.8356\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.4246 - acc: 0.8718 - val_loss: 0.4569 - val_acc: 0.8402\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.4172 - acc: 0.8708 - val_loss: 0.4497 - val_acc: 0.8311\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.4096 - acc: 0.8679 - val_loss: 0.4441 - val_acc: 0.8311\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.4026 - acc: 0.8718 - val_loss: 0.4386 - val_acc: 0.8356\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.3959 - acc: 0.8728 - val_loss: 0.4347 - val_acc: 0.8356\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.3893 - acc: 0.8738 - val_loss: 0.4292 - val_acc: 0.8402\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.3833 - acc: 0.8689 - val_loss: 0.4256 - val_acc: 0.8356\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.3774 - acc: 0.8728 - val_loss: 0.4237 - val_acc: 0.8402\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3716 - acc: 0.8708 - val_loss: 0.4203 - val_acc: 0.8402\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.3662 - acc: 0.8757 - val_loss: 0.4156 - val_acc: 0.8402\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3613 - acc: 0.8728 - val_loss: 0.4126 - val_acc: 0.8402\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3563 - acc: 0.8718 - val_loss: 0.4090 - val_acc: 0.8402\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.3519 - acc: 0.8728 - val_loss: 0.4069 - val_acc: 0.8356\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3474 - acc: 0.8748 - val_loss: 0.4032 - val_acc: 0.8402\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3438 - acc: 0.8738 - val_loss: 0.4035 - val_acc: 0.8402\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.3398 - acc: 0.8757 - val_loss: 0.4012 - val_acc: 0.8402\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 0.3359 - acc: 0.8777 - val_loss: 0.3980 - val_acc: 0.8402\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3328 - acc: 0.8777 - val_loss: 0.3984 - val_acc: 0.8402\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3294 - acc: 0.8777 - val_loss: 0.3957 - val_acc: 0.8402\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3261 - acc: 0.8855 - val_loss: 0.3920 - val_acc: 0.8447\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.3232 - acc: 0.8796 - val_loss: 0.3909 - val_acc: 0.8447\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3205 - acc: 0.8796 - val_loss: 0.3939 - val_acc: 0.8311\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3178 - acc: 0.8826 - val_loss: 0.3887 - val_acc: 0.8447\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3152 - acc: 0.8816 - val_loss: 0.3888 - val_acc: 0.8265\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.3124 - acc: 0.8796 - val_loss: 0.3850 - val_acc: 0.8447\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 0.3111 - acc: 0.8796 - val_loss: 0.3886 - val_acc: 0.8311\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.3085 - acc: 0.8826 - val_loss: 0.3903 - val_acc: 0.8311\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.3063 - acc: 0.8845 - val_loss: 0.3859 - val_acc: 0.8356\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.3046 - acc: 0.8845 - val_loss: 0.3846 - val_acc: 0.8356\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.3021 - acc: 0.8865 - val_loss: 0.3838 - val_acc: 0.8356\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.3003 - acc: 0.8865 - val_loss: 0.3847 - val_acc: 0.8356\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2988 - acc: 0.8865 - val_loss: 0.3820 - val_acc: 0.8311\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2972 - acc: 0.8924 - val_loss: 0.3820 - val_acc: 0.8356\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2945 - acc: 0.8885 - val_loss: 0.3844 - val_acc: 0.8311\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.2938 - acc: 0.8904 - val_loss: 0.3871 - val_acc: 0.8356\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.2924 - acc: 0.8894 - val_loss: 0.3796 - val_acc: 0.8311\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2911 - acc: 0.8924 - val_loss: 0.3805 - val_acc: 0.8356\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.2893 - acc: 0.8924 - val_loss: 0.3828 - val_acc: 0.8356\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 22us/step - loss: 0.2882 - acc: 0.8904 - val_loss: 0.3825 - val_acc: 0.8356\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2871 - acc: 0.8924 - val_loss: 0.3790 - val_acc: 0.8356\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2850 - acc: 0.8914 - val_loss: 0.3814 - val_acc: 0.8356\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2837 - acc: 0.8914 - val_loss: 0.3767 - val_acc: 0.8311\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2828 - acc: 0.8904 - val_loss: 0.3808 - val_acc: 0.8356\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2818 - acc: 0.8943 - val_loss: 0.3814 - val_acc: 0.8356\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.2809 - acc: 0.8943 - val_loss: 0.3792 - val_acc: 0.8356\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2790 - acc: 0.8904 - val_loss: 0.3766 - val_acc: 0.8356\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.2783 - acc: 0.8933 - val_loss: 0.3781 - val_acc: 0.8356\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2774 - acc: 0.8924 - val_loss: 0.3812 - val_acc: 0.8356\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 0.2745 - acc: 0.8943 - val_loss: 0.3727 - val_acc: 0.8265\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2759 - acc: 0.8963 - val_loss: 0.3777 - val_acc: 0.8356\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2740 - acc: 0.8953 - val_loss: 0.3749 - val_acc: 0.8356\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2732 - acc: 0.8914 - val_loss: 0.3740 - val_acc: 0.8311\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2724 - acc: 0.8914 - val_loss: 0.3764 - val_acc: 0.8356\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 23us/step - loss: 0.2718 - acc: 0.8933 - val_loss: 0.3742 - val_acc: 0.8356\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 0.2694 - acc: 0.8933 - val_loss: 0.3813 - val_acc: 0.8402\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 0.2696 - acc: 0.8933 - val_loss: 0.3778 - val_acc: 0.8356\n",
      "219/219 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9086758026249333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three hidden layers\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "#specify optimization, loss function and accuracy\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#train the model with fit\n",
    "# Specify training data set, batch size, epochs (how long) and validation\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))\n",
    "# Evaluate on the test data\n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gcr.io/arrikto-public/tensorflow-1.14.0-notebook-cpu:kubecon-workshop",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "pipeline_description": "",
   "pipeline_name": "housepredictiondata",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
